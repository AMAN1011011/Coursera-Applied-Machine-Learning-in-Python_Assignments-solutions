{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"assignment3.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1p2SoYbUvN-EUzbIIhDkkijkMHK_miTcD\n",
        "\n",
        "---\n",
        "\n",
        "_You are currently looking at **version 0.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the Jupyter Notebook FAQ course resource._\n",
        "\n",
        "---\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BUsIzbDq5abt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "b1OjFIlh5cTU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 1\n",
        "Import the data from `assets/fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
        "\n",
        "*This function should return a float between 0 and 1.* \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3OwuV58E5gCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_one():\n",
        "    \n",
        "    df = pd.read_csv('assets/fraud_data.csv')\n",
        "    seg = df.iloc[:,-1]\n",
        "    return float(seg[seg.values==1].count()/seg.count())\n",
        "\n",
        "answer_one()"
      ],
      "metadata": {
        "id": "6Q0pM__S5hqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('assets/fraud_data.csv')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
      ],
      "metadata": {
        "id": "2SKOIN7t5kly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 2\n",
        "\n",
        "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
        "\n",
        "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qdc7tNqW5rfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ef answer_two():\n",
        "    from sklearn.dummy import DummyClassifier\n",
        "    from sklearn.metrics import recall_score, accuracy_score\n",
        "    \n",
        "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "    y_dummy_predictions = dummy_majority.predict(X_test)\n",
        "\n",
        "    return accuracy_score(y_test, y_dummy_predictions), recall_score(y_test, y_dummy_predictions)\n",
        "answer_two()"
      ],
      "metadata": {
        "id": "fwaa_i4W5r1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 3\n",
        "\n",
        "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
        "\n",
        "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V4qw1mIt5vbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_three():\n",
        "    from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    svm = SVC().fit(X_train, y_train)\n",
        "    svm_predicted_mc = svm.predict(X_test)\n",
        "\n",
        "    return accuracy_score(y_test, svm_predicted_mc), recall_score(y_test, svm_predicted_mc), precision_score(y_test, svm_predicted_mc)\n",
        "answer_three()\n",
        "\n"
      ],
      "metadata": {
        "id": "FXpjSfOh5zXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 4\n",
        "\n",
        "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
        "\n",
        "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EzUG1fIn5178"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_four():\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    svm = SVC(gamma=1e-07,C=1e9).fit(X_train, y_train)\n",
        "    svm_predicted_mc = svm.decision_function(X_test) > -220\n",
        "    confusion_mc = confusion_matrix(y_test, svm_predicted_mc)\n",
        "    \n",
        "    return confusion_mc\n",
        "answer_four()\n"
      ],
      "metadata": {
        "id": "YogAejjp53-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 5\n",
        "\n",
        "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
        "\n",
        "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
        "\n",
        "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
        "\n",
        "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
        "\n",
        "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "QKcDul5Q5-Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "def answer_five():\n",
        "    \n",
        "#     %matplotlib notebook\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "    \n",
        "    y_scores_lr = LogisticRegression().fit(X_train,y_train).decision_function(X_test)\n",
        "    precision,recall,thresholds = precision_recall_curve(y_test,y_scores_lr)\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores_lr)\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(precision,recall)\n",
        "    plt.plot(fpr_lr,tpr_lr)\n",
        "    \n",
        "    return (0.83,0.94)\n",
        "\n",
        "answer_five()"
      ],
      "metadata": {
        "id": "BT4II0l35-ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"### Question 6\n",
        "\n",
        "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation. (Suggest to use `solver='liblinear'`, more explanation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html))\n",
        "\n",
        "`'penalty': ['l1', 'l2']`\n",
        "\n",
        "`'C':[0.01, 0.1, 1, 10]`\n",
        "\n",
        "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
        "\n",
        "|      \t| `l1` \t| `l2` \t|\n",
        "|:----:\t|----\t|----\t|\n",
        "| **`0.01`** \t|    ?\t|   ? \t|\n",
        "| **`0.1`**  \t|    ?\t|   ? \t|\n",
        "| **`1`**    \t|    ?\t|   ? \t|\n",
        "| **`10`**   \t|    ?\t|   ? \t|\n",
        "\n",
        "<br>\n",
        "\n",
        "*This function should return a 4 by 2 numpy array with 8 floats.* \n",
        "\n",
        "*Note: do not return a DataFrame, just the values denoted by `?` in a numpy array.*\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z3wuQm2m6B97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_six():\n",
        "    \n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    \n",
        "    grid_values={'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10]}\n",
        "    lr = LogisticRegression().fit(X_train,y_train)\n",
        "    \n",
        "    # Number of folds included as a parameter in GridSearchCV. Default cv=3.\n",
        "    lr_custom = GridSearchCV(lr,param_grid=grid_values,scoring='recall',cv=3)\n",
        "    lr_custom.fit(X_train,y_train)\n",
        "\n",
        "    return lr_custom.cv_results_['mean_test_score'].reshape(4,2)\n",
        "\n",
        "answer_six()\n",
        "\n",
        "\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Use the following function to help visualize results from the grid search\n",
        "def GridSearch_Heatmap(scores):\n",
        "#     %matplotlib notebook\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10])\n",
        "    plt.yticks(rotation=0);\n",
        "\n",
        "#GridSearch_Heatmap(answer_six())"
      ],
      "metadata": {
        "id": "WzUkha796EFJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}